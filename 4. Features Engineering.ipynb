{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "[Context](#Co)<br>\n",
    "[Import packages and data](#0)<br>\n",
    "    \n",
    "1. [**Factors representation**](#Fac)<br>\n",
    "    \n",
    "2. [**Historic representation**](#Hi)<br>\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Co\"></a>\n",
    "# Context\n",
    "\n",
    "The **World Happiness Report** is a landmark survey of the state of global happiness from 2015 to 2019 according to 6 main factors:\n",
    "* economic production, \n",
    "* social support, \n",
    "* life expectancy, freedom, \n",
    "* absence of corruption, \n",
    "* and generosity\n",
    "\n",
    "### Purposes of the project\n",
    "<ins> Data analysis: </ins>\n",
    "1. Give a clear picture of happiness around the world in 2019\n",
    "2. Analyse trends in happiness from 2015 to 2019\n",
    "\n",
    "<ins> Forecasting with Machine Learning</ins>(\\*)\n",
    "1. Can we predict a country happiness if we know the gdp per capita, life expectancy and other factors values?\n",
    "2. Can we predict a country happiness thanks to its history (happiness+factors)?\n",
    "\n",
    "(\\*) *Although data don't contain related information, the global pandemic may have a tremendous impact on the results*\n",
    "\n",
    "You can find the whole presentation and information about the data in the **Project Presentation** notebook\n",
    "\n",
    "### Workflow\n",
    "* Cleaning\n",
    "* EDA\n",
    "* Data Visualization\n",
    "* **Features Engineering**\n",
    "* Machine Learning\n",
    "\n",
    "-----\n",
    "\n",
    "Features Engineering is the process of transforming the data into a better representation that maximizes the efficiency of your machine learning models.\n",
    "\n",
    "In this notebook, we will create a dataset for each forecasting purpose:\n",
    "* predict happiness thanks to factors: factor dataset\n",
    "* predicth happiness thanks to past years historic: historic dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"0\"></a>\n",
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: (705, 11)\n"
     ]
    }
   ],
   "source": [
    "# import cleaned and normalized data\n",
    "df = pd.read_csv('data/data_clean_norm.csv')\n",
    "print(\"data dimension:\",df.shape)\n",
    "\n",
    "# list of factors\n",
    "l_factors = ['life_expectancy', 'gdp_per_capita', 'social_support', \n",
    "             'freedom','generosity', 'corruption_perception'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"Fac\"></a>\n",
    "# Factors representation\n",
    "\n",
    "* **Train set** (train model): happiness and factors from 2016 to 2018\n",
    "* **Test set** (test model accuracy): happiness and factors in 2019\n",
    "* **Infer set** (our objectiv): factors in 2020 (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = df.copy()\n",
    "\n",
    "# sort values by country and years for groupby computing\n",
    "fact_df.sort_values(by=[\"country\",\"year\"],ascending=True)\n",
    "\n",
    "# Get year-1 happiness value by shifting values per country\n",
    "fact_df['happiness_scoreP1'] = fact_df.groupby('country')['happiness_score'].shift()\n",
    "\n",
    "# set country as index\n",
    "fact_df.set_index(\"country\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert categorical variable region into dumy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummify region variable\n",
    "df_dummies_reg = pd.get_dummies(fact_df['region']).reset_index().drop_duplicates().set_index(\"country\")\n",
    "\n",
    "# merge dummies with source dataframe\n",
    "fact_df = pd.merge(fact_df, df_dummies_reg, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "# drop happiness_rank and region\n",
    "fact_df.drop(columns=[\"happiness_rank\",\"region\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df[fact_df['year'].isin([2018])].to_csv('data/fact_train_set.csv', index=True)\n",
    "\n",
    "fact_df[fact_df['year'].isin([2019])].to_csv('data/fact_test_set.csv', index=True)\n",
    "\n",
    "# hist_infer_set.to_csv('data/_hist_infer_set.csv', index=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"Hi\"></a>\n",
    "# Historic representation\n",
    "\n",
    "We decide to predict happiness in 2020 with 3 years long history of data (happiness and factors). To do so,\n",
    "we have 3 datasets to build:\n",
    "* **Train set** (train model): happiness in 2018 and data from 2015 to 2017\n",
    "* **Test set** (test model accuracy: happiness in 2019 and data from 2016 to 2018\n",
    "* **Infer set** (our objectiv): data from 2017 to 2019 to forecast 2020 happiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get data history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_N3(df, year, l_var, infer=False):\n",
    "    \"\"\"\n",
    "    This functions transforms our data into a dataset containing\n",
    "    for each country, happiness score for a selected year\n",
    "    and variables for the 3 previous years\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        our dataset\n",
    "        \n",
    "    year: int\n",
    "        selected year\n",
    "        \n",
    "    l_var: list\n",
    "        historic variables\n",
    "        \n",
    "    infer: boolean (default:False)\n",
    "        if True: create the dataset with only predicting variables (historic)\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    DataFrame\n",
    "        transformed dataset\n",
    "    \"\"\"\n",
    "    if infer:\n",
    "        df_y = df[df[\"year\"]==year-1]['region']\n",
    "    else:\n",
    "        df_y = df[df[\"year\"]==year][l_var]\n",
    "    \n",
    "    \n",
    "    for i in range(1,4):\n",
    "        df_p = df[df[\"year\"]==year-i][l_var]\n",
    "        df_p.drop(columns=[\"year\",\"region\",\"happiness_rank\"],inplace=True)\n",
    "        \n",
    "        df_p.rename(\n",
    "            columns=dict(zip(df_p.columns.tolist(),[col+\"P\"+str(i) for col  in df_p.columns.tolist()])),\n",
    "            inplace=True)\n",
    "\n",
    "        df_y = pd.merge(df_y, df_p, left_index=True, right_index=True, how=\"inner\")\n",
    "        \n",
    "    if not infer:\n",
    "        df_y.drop(columns=[col for col in df.columns if col not in [\"year\",\"happiness_score\",\"region\"]],inplace=True)\n",
    "        \n",
    "    \n",
    "    return(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.set_index(\"country\",inplace=True)\n",
    "\n",
    "hist_train_set = get_historic_N3(df, 2018, df.columns.tolist())\n",
    "\n",
    "hist_test_set = get_historic_N3(df, 2019, df.columns.tolist())\n",
    "\n",
    "hist_infer_set=get_historic_N3(df,2020,df.columns.tolist(), infer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert categorical variable region into dumy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_train_set = pd.merge(hist_train_set, pd.get_dummies(hist_train_set['region']), left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "hist_test_set = pd.merge(hist_test_set, pd.get_dummies(hist_test_set['region']), left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "hist_infer_set = pd.merge(hist_infer_set, pd.get_dummies(hist_infer_set['region']), left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_train_set.to_csv('data/hist_train_set.csv', index=True)\n",
    "\n",
    "hist_test_set.to_csv('data/hist_test_set.csv', index=True)\n",
    "\n",
    "# hist_infer_set.to_csv('data/_hist_infer_set.csv', index=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
