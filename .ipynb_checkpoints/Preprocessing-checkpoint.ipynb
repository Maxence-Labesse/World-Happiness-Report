{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Données N-3 à N-1\n",
    "* Train: 2018=f(2017, 2016, 2015)\n",
    "* Test 2019=f(2018, 2017, 2015)\n",
    "* Inférence 2020=f(2019, 2018, 2017)\n",
    "\n",
    "\n",
    "Tester le drift ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "[Context](#Co)<br>\n",
    "[Import packages and data](#0)<br>\n",
    "    \n",
    "[**Data representation**](#Da)<br>\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Co\"></a>\n",
    "# Context\n",
    "\n",
    "The **World Happiness Report** is a landmark survey of the state of global happiness from 2015 to 2019 according to 6 main factors:\n",
    "* economic production, \n",
    "* social support, \n",
    "* life expectancy, freedom, \n",
    "* absence of corruption, \n",
    "* and generosity\n",
    "\n",
    "### Purposes of the project\n",
    "<ins> Data analysis: </ins>\n",
    "1. Give a clear picture of happiness around the world in 2019\n",
    "2. Analyse trends in happiness from 2015 to 2019\n",
    "    \n",
    "<ins> Forecasting with Machine Learning</ins>(*)\n",
    "1. How happy will countries be in 2020 ?\n",
    "2. In which countries happiness will increase in 2020 ?\n",
    "\n",
    "(\\*) *Although data don't contain related information, the global pandemic may have a tremendous impact on the results*\n",
    "\n",
    "You can find the whole presentation and information about the data in the **Project Presentation** notebook\n",
    "\n",
    "### Workflow\n",
    "* Cleaning\n",
    "* EDA\n",
    "* Data Visualization\n",
    "* **Preprocessing**\n",
    "* Machine Learning\n",
    "\n",
    "Before we apply our machine learning models to forecast happiness in 2020, we need to find the best data representation that will allow the models to be the most efficient.\n",
    "\n",
    "In our case, we will modify our dataset to predict 2020 happiness according to a 3 years long historic happiness factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"0\"></a>\n",
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: (705, 11)\n"
     ]
    }
   ],
   "source": [
    "# import cleaned and normalized data\n",
    "df = pd.read_csv('data/data_clean_norm.csv')\n",
    "print(\"data dimension:\",df.shape)\n",
    "# \n",
    "df.set_index(\"country\",inplace=True)\n",
    "\n",
    "# list of factors\n",
    "l_factors = ['life_expectancy', 'gdp_per_capita', 'social_support', \n",
    "             'freedom','generosity', 'corruption_perception'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"Da\"></a>\n",
    "# Data representation\n",
    "\n",
    "In our case, we decide to predict happiness in 2020 with 3 years long historic of data (happiness and factors). To do so,\n",
    "we have 3 datasets to build:\n",
    "* **Train set** (train model): happiness in 2018 and data from 2015 to 2017\n",
    "* **Test set** (test model accuracy: happiness in 2019 and data from 2016 to 2018\n",
    "* **Infer set** (our objectiv) : data from 2017 to 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get historic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_N3(df, year, l_var, infer=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if infer:\n",
    "        df_y = df[df[\"year\"]==year-1]['region']\n",
    "    else:\n",
    "        df_y = df[df[\"year\"]==year][l_var]\n",
    "    \n",
    "    \n",
    "    for i in range(1,4):\n",
    "        df_p = df[df[\"year\"]==year-i][l_var]\n",
    "        df_p.drop(columns=[\"year\",\"region\",\"happiness_rank\"],inplace=True)\n",
    "        \n",
    "        df_p.rename(\n",
    "            columns=dict(zip(df_p.columns.tolist(),[col+\"P\"+str(i) for col  in df_p.columns.tolist()])),\n",
    "            inplace=True)\n",
    "\n",
    "        df_y = pd.merge(df_y, df_p, left_index=True, right_index=True, how=\"inner\")\n",
    "        \n",
    "    if not infer:\n",
    "        df_y.drop(columns=[col for col in df.columns if col not in [\"year\",\"happiness_score\",\"region\"]],inplace=True)\n",
    "        \n",
    "    \n",
    "    return(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = get_historic_N3(df, 2018, df.columns.tolist())\n",
    "\n",
    "test_set = get_historic_N3(df, 2019, df.columns.tolist())\n",
    "\n",
    "infer_set=get_historic_N3(df,2020,df.columns.tolist(), infer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert categorical variable into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.merge(train_set, pd.get_dummies(train_set['region']), left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "test_set = pd.merge(test_set, pd.get_dummies(test_set['region']), left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "infer_set = pd.merge(infer_set, pd.get_dummies(infer_set['region']), left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('data/train_set.csv', index=True)\n",
    "\n",
    "test_set.to_csv('data/test_set.csv', index=True)\n",
    "\n",
    "infer_set.to_csv('data/infer_set.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
