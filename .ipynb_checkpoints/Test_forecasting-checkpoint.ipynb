{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "**Regression linéaire tuto Python:** \n",
    "* https://medium.com/all-about-ml/linear-regression-d41a6a5dcab6\n",
    "* https://anaconda.org/sanchitiitr/linear-regression-model/notebook\n",
    "\n",
    "**Polynomiale:**\n",
    "* https://medium.com/analytics-vidhya/understanding-polynomial-regression-5ac25b970e18 (voir cost function)\n",
    "* https://medium.com/@rushilp2311/in-this-article-we-will-explore-more-about-regression-algorithm-ca3c5594a0b0 (sklearn.preprocessing import PolynomoalFeatures)\n",
    "* https://towardsdatascience.com/polynomial-regression-bbe8b9d97491\n",
    "\n",
    "**Random Forest**\n",
    "* https://medium.com/swlh/random-forest-and-its-implementation-71824ced454f\n",
    "\n",
    "**Autre:**\n",
    "* Stepwise ?\n",
    "* A la fin, un tableau récapitulatif modèle + métrique\n",
    "* Overfitting : https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 questions:\n",
    "* Peut on prédire l'happiness quand on connait les facteurs d'un pays?\n",
    "\n",
    "* Peut on prédire h'appiness uniquement avec son historique des années précédentes ?\n",
    "Puisqu'on a pas de données sur 2020, on doit préduire l'happiness uniquement avec l'historique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "[Context](#Co)<br>\n",
    "[Import packages and data](#0)<br>\n",
    "    \n",
    "[**Data representation**](#Da)<br>\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"0\"></a>\n",
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaned and normalized data\n",
    "train_set = pd.read_csv('data/train_set.csv', index_col=\"country\")\n",
    "test_set = pd.read_csv('data/test_set.csv', index_col=\"country\")\n",
    "\n",
    "# drop region and year\n",
    "train_set.drop(columns=['year','region'],inplace=True)\n",
    "test_set.drop(columns=['year','region'],inplace=True)\n",
    "infer_set.drop(columns=['region'],inplace=True)\n",
    "\n",
    "# list of factors\n",
    "l_factors = ['life_expectancy', 'gdp_per_capita', 'social_support', \n",
    "             'freedom','generosity', 'corruption_perception']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "------------\n",
    "<a name=\"Da\"></a>\n",
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.copy().drop(columns=['happiness_score'])\n",
    "y_train = train_set[\"happiness_score\"].copy()\n",
    "\n",
    "X_test = test_set.copy().drop(columns=['happiness_score'])\n",
    "y_test = test_set[\"happiness_score\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_metrics(y_test, y_pred_test, y_train=[], y_pred_train=[], method=\"\", display=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    d_mse = {\"test\": None,\"train\": None}\n",
    "    d_mse[\"test\"] = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    if display:\n",
    "        print(method+\" test_set mse:\", d_mse[\"test\"])\n",
    "    \n",
    "    if len(y_train)>0:\n",
    "        d_mse[\"train\"] = mean_squared_error(y_train, y_pred_train)\n",
    "        if display:\n",
    "            print(method+\" train_set mse:\", d_mse[\"train\"])\n",
    "\n",
    "    return d_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Happiness year N = Happiness year N-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark test_set mse: 17.492573441032466\n"
     ]
    }
   ],
   "source": [
    "y_pred_bench = test_set[\"happiness_scoreP1\"]\n",
    "\n",
    "benchmark_mse = train_test_metrics(y_test=y_test, y_pred_test=y_pred_bench, method=\"benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est notre référence pour analyser les algos suivants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire sans selection de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression() \n",
    "linear_fit = model.fit(X_train, y_train)\n",
    "y_pred_lin = linear_fit.predict(X_test)\n",
    "y_train_pred_lin = linear_fit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression test_set mse: 32.71871849467362\n",
      "linear regression train_set mse: 9.09998014942466\n"
     ]
    }
   ],
   "source": [
    "lreg_metrics = train_test_metrics(y_test, y_pred_lin, y_train, y_train_pred_lin, method=\"linear regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over fitting !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Régression linéaire avec selection de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corruption_perceptionP1',\n",
       " 'generosityP1',\n",
       " 'Australia and New Zealand',\n",
       " 'Central and Eastern Europe',\n",
       " 'Eastern Asia',\n",
       " 'Latin America and Caribbean',\n",
       " 'Middle East and Northern Africa',\n",
       " 'North America',\n",
       " 'Southeastern Asia',\n",
       " 'Southern Asia',\n",
       " 'Sub-Saharan Africa']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_var_remove = [\"gdp_per_capitaP2\", \"life_expectancyP2\", \"gdp_per_capitaP3\", \"happiness_scoreP2\",\"corruption_perceptionP2\",\n",
    "                \"social_supportP2\", \"generosityP2\",\"freedomP2\",\"life_expectancyP3\",\"corruption_perceptionP3\",\n",
    "                \"happiness_scoreP3\",\"Western Europe\",\"social_supportP3\",\"freedomP3\", \"generosityP3\",\"social_supportP1\",\n",
    "                \"gdp_per_capitaP1\",\"happiness_scoreP1\", \"freedomP1\",\"life_expectancyP1\"]\n",
    "\n",
    "\n",
    "X_train_sel = X_train.copy().drop(columns=l_var_remove)\n",
    "X_test_sel = X_test.copy().drop(columns=l_var_remove)\n",
    "\n",
    "\n",
    "vif = pd.DataFrame() #Let us show th VIF scores in a data frame\n",
    "vif[\"Features\"] = X_train_sel.columns\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train_sel.values, i) for i in range(X_train_sel.shape[1])] #variance_inflation_factor calculates the scores #for each Feature\n",
    "vif.sort_values(by=\"VIF Factor\", ascending=False)\n",
    "\n",
    "\n",
    "display(vif.Features.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with RSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination, or RFE for short, is a popular feature selection algorithm.\n",
    "\n",
    "RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([19, 15, 10, 18,  1, 12,  7, 21, 14, 13, 17,  3,  5, 16, 20, 11,  9,\n",
       "       22,  8,  4,  6,  1,  1,  1,  2,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model = LinearRegression()\n",
    "selector = RFE(model, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "display(selector.support_)\n",
    "\n",
    "display(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 21, 22, 23, 25, 26, 27, 28, 29, 30]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['happiness_scoreP1',\n",
       " 'Australia and New Zealand',\n",
       " 'Central and Eastern Europe',\n",
       " 'Eastern Asia',\n",
       " 'Middle East and Northern Africa',\n",
       " 'North America',\n",
       " 'Southeastern Asia',\n",
       " 'Southern Asia',\n",
       " 'Sub-Saharan Africa',\n",
       " 'Western Europe']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector_idx = [i for i in range(len(selector.support_)) if selector.support_[i]]\n",
    "display(selector_idx)\n",
    "\n",
    "selected_var = [X_train.columns[i] for i in selector_idx]\n",
    "display(selected_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear varsel mse test: 14.573936484712481\n",
      "linear varsel mse train: 13.195777478829317\n"
     ]
    }
   ],
   "source": [
    "X_train_sel= X_train[selected_var]\n",
    "X_test_sel = X_test[selected_var]\n",
    "\n",
    "\n",
    "model = LinearRegression() \n",
    "linear_varsel_fit = model.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred_lin_varsel = linear_varsel_fit.predict(X_test_sel)\n",
    "y_train_pred_lin_varsel = linear_varsel_fit.predict(X_train_sel)\n",
    "\n",
    "\n",
    "linear_varsel_mse_test = mean_squared_error(y_test, y_pred_lin_varsel)\n",
    "linear_varsel_mse_train = mean_squared_error(y_train, y_train_pred_lin_varsel)\n",
    "\n",
    "print(\"linear varsel mse test:\",linear_varsel_mse_test)\n",
    "print(\"linear varsel mse train:\",linear_varsel_mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_algo(df_train, df_test, target, l_features, y_test_benchmark):\n",
    "    \"\"\"\n",
    "    Compare different Machine Learning Alrogithms for regression\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    X_train = df_train[l_features].copy()\n",
    "    y_train = df_train[target].copy()\n",
    "\n",
    "    X_test = df_test[l_features].copy()\n",
    "    y_test = df_test[target].copy()\n",
    "    \n",
    "    # Benchmark\n",
    "    benchmark_mse = train_test_metrics(y_test=y_test, y_pred_test=y_pred_bench, \n",
    "                                            method=\"Benchmark\", display=False)\n",
    "    \n",
    "    # Linear regression\n",
    "    model = LinearRegression() \n",
    "    linear_fit = model.fit(X_train, y_train)\n",
    "    y_pred_lin = linear_fit.predict(X_test)\n",
    "    y_train_pred_lin = linear_fit.predict(X_train)\n",
    "    \n",
    "    lreg_mse = train_test_metrics(y_test, y_pred_lin, y_train, y_train_pred_lin, \n",
    "                                                       method=\"Linear regression\", display=False)\n",
    "    \n",
    "    # Polynomial regression\n",
    "    poly_reg = PolynomialFeatures(degree = 3)\n",
    "    X_train_poly = poly_reg.fit_transform(X_train_sel)\n",
    "    X_test_poly = poly_reg.transform(X_test_sel)\n",
    "\n",
    "    reg2_mse = train_test_metrics(y_test, y_test_pred_reg2, y_train, y_train_pred_reg2, \n",
    "                                                       method=\"polynomial (square) regression\", display=False)\n",
    "    \n",
    "    # Random Forest\n",
    "    l_n_estimators= np.random.uniform(low=20, high=500, size=40).astype(int)\n",
    "    l_max_features= ['auto', 'log2']\n",
    "    l_max_depth= [3, 4, 5, 6, 7, 8]\n",
    "    l_min_samples_split= [5, 10, 15, 20]\n",
    "    \n",
    "    for i in range(100):\n",
    "        n_estimators = random.choice(l_n_estimators)\n",
    "        max_features = random.choice(l_max_features)\n",
    "        max_depth = random.choice(l_max_depth)\n",
    "        min_samples_split = random.choice(l_min_samples_split)\n",
    "\n",
    "        RF_reg = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features,\n",
    "                                       max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "        RF_reg.fit(X_train_sel, y_train)\n",
    "        y_train_pred_rf = RF_reg.predict(X_train_sel)\n",
    "        y_test_pred_rf = RF_reg.predict(X_test_sel)\n",
    "    \n",
    "        rf_mse = train_test_metrics(y_test, y_test_pred_rf, y_train, y_train_pred_rf, \n",
    "                                                       method=\"RF\", display=False)\n",
    "    \n",
    "        if (abs(rf_test_mse-rf_train_mse)<2 and rf_test_mse<best_valid_model) or i==1:\n",
    "            best_valid_model_mse = rf_test_mse\n",
    "            best_valid_model_mse_train =rf_train_mse\n",
    "            best_model_n_estimators = n_estimators \n",
    "            best_model_max_features = max_features\n",
    "            best_model_max_depth = max_depth\n",
    "            best_model_min_samples_split = min_samples_split\n",
    "    \n",
    "    \n",
    "    # Display\n",
    "    df_mse = pd.DataFrame(index=[\"Benchmark\", \"Linear Regression\", \"Polynomial (square) Regression\", \"Random Forest\"], \n",
    "                           columns=['Test MSE', \"Train MSE\"])\n",
    "    \n",
    "    df_mse.loc[\"Benchmark\"] = list(benchmark_mse.values())\n",
    "    df_mse.loc[\"Linear Regression\"] = list(lreg_mse.values())\n",
    "    df_mse.loc[\"Polynomial (square) Regression\"] = list(reg2_mse.values())\n",
    "    df_mse.loc[\"Random Forest\"] = list(rf_mse.values())\n",
    "    \n",
    "    display(df_mse)\n",
    "    \n",
    "    print(\"RF params: \\nn_estimators:\",best_model_n_estimators,\n",
    "          \"/ max_features:\",best_model_max_features,\n",
    "          \"/ max_depth:\",best_model_max_depth,\n",
    "          \"/ min_samples_split\",best_model_min_samples_split)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Train MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benchmark</th>\n",
       "      <td>17.4926</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>13.6904</td>\n",
       "      <td>13.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial (square) Regression</th>\n",
       "      <td>1.27789e+07</td>\n",
       "      <td>13.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>19.147</td>\n",
       "      <td>15.1292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Test MSE Train MSE\n",
       "Benchmark                           17.4926      None\n",
       "Linear Regression                   13.6904   13.0592\n",
       "Polynomial (square) Regression  1.27789e+07   13.8641\n",
       "Random Forest                        19.147   15.1292"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF params: \n",
      "n_estimators: 356 / max_features: auto / max_depth: 4 / min_samples_split 15\n"
     ]
    }
   ],
   "source": [
    "compare_algo(train_set, test_set, \"happiness_score\", l_var, test_set[\"happiness_scoreP1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
